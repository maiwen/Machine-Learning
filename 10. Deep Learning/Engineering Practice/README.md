# 实践方法论

要成功地使用深度学习技术，仅仅知道存在哪些算法和解释它们为何有效的原理是不够的。
一个优秀的机器学习实践者还需要知道如何**针对具体应用挑选一个合适的算法**以及如何**监控**，并**根据实验反馈改进机器学习系统**。
在机器学习系统的日常开发中，
实践者需要决定是否收集更多的数据、增加或减少模型容量、添加或删除正则化项、改进模型的优化、改进模型的近似推断或调试模型的软件实现。
尝试这些操作都需要大量时间，因此确定正确的做法，而不盲目猜测尤为重要。

在实践中，正确使用一个普通算法通常比草率地使用一个不清楚的算法效果更好。
正确应用一个算法需要掌握一些相当简单的方法论。
我们建议参考以下几个实践设计流程：

* 确定目标——使用什么样的误差度量，并为此误差度量指定目标值。这些目标和误差度量取决于该应用旨在解决的问题。
* 尽快建立一个端到端的工作流程，包括估计合适的性能度量。
* 搭建系统，并确定性能瓶颈。检查哪个部分的性能差于预期，以及是否是因为过拟合、欠拟合，或者数据或软件缺陷造成的。
* 根据具体观察反复地进行增量式的改动，如收集新数据、调整超参数或改进算法。

## 1. 性能度量
确定目标，即使用什么误差度量，是必要的第一步，因为误差度量将指导接下来的所有工作。

### 训练数据的数量
训练数据的数量会因为各种原因受到限制。
当目标是打造现实世界中最好的产品或服务时，我们通常需要收集更多的数据，但必须确定进一步减少误差的价值，
并**与收集更多数据的成本做权衡**。数据收集会耗费时间、金钱，或带来人体痛苦（例如，收集人体医疗测试数据）。
科研中，目标通常是在某个确定基准下探讨哪个算法更好，一般会固定训练集，不允许收集更多的数据。

### 度量的选择

#### 精确度 （precision）和召回率 （recall）
我们通常会度量一个系统的准确率，或等价地，错误率。然而，许多应用需要更高级的度量。

有时，**一种错误可能会比另一种错误更严重**。
例如，垃圾邮件检测系统会有两种错误：将正常邮件错误地归为垃圾邮件，将垃圾邮件错误地归为正常邮件。
我们希望度量某种形式的总代价，其中拦截正常邮件比允许垃圾邮件通过的代价更高，而不是度量垃圾邮件分类的错误率。

有时，我们需要训练检测某些**罕见事件的二元分类器**。

例如，我们可能会为一种罕见疾病设计医疗测试。假设每一百万人中只有一人患病。
我们只需要让分类器一直报告没有患者，就能轻易地在检测任务上实现99.9999％的正确率。显然，**正确率很难描述这种系统的性能**。

解决这个问题的方法是度量精度 （precision）和召回率 （recall）。
精度是模型报告的检测正确的比率，而召回率则是真实事件被检测到的比率。
检测器永远报告没有患者，会得到一个完美的精度，但召回率为零。
而报告每个人都是患者的检测器会得到一个完美的召回率，但是精度会等于人群中患有该病的比例（在我们的例子中是0.0001％，即每一百万人只有一人患病）。

当使用精度和召回率时，我们通常会画**PR曲线** （PR curve），y轴表示精度，x轴表示召回率。
例如，我们将前馈网络设计为检测一种疾病，估计一个医疗结果由特征 x 表示的人患病的概率为 。
每当这个得分超过某个阈值时，我们报告检测结果。通过调整阈值，我们能**权衡精度和召回率**。
在很多情况下，我们希望用一个数而不是曲线来概括分类器的性能。要做到这一点，我们可以将精度p和召回率r转换为F分数 （F-score）
F = 2pr / (p+r)

另一种方法是报告PR曲线下方的总面积。

#### 覆盖
如果机器学习算法能够估计所作判断的置信度，这将会非常有用，特别是在错误判断会导致严重危害，而人工操作员能够偶尔接管的情况下。

覆盖是机器学习系统能够产生响应的样本所占的比率。我们权衡覆盖和精度。一个系统可以通过拒绝处理任意样本的方式来达到100％的精度，但是覆盖降到了0％。

还有许多其他的性能度量。最重要的是首先要确定改进哪个性能度量，然后专心提高性能度量。如果没有明确的目标，那么我们很难判断机器学习系统上的改动是否有所改进。

## 2. 基准模型
确定性能度量和目标后，任何实际应用的下一步是尽快建立一个合理的端到端的系统。
下面提供了关于不同情况下使用哪种算法作为第一基准方法的推荐。值得注意的是，深度学习研究进展迅速，很快可能会有更好的默认算法。

根据问题的复杂性，项目开始时可能无须使用深度学习。
如果只需正确地选择几个线性权重就可能解决问题，那么项目可以开始于一个简单的统计模型，如逻辑回归。

如果问题属于“AI-完全”类的，如对象识别、语音识别、机器翻译等，那么项目开始于一个合适的深度学习模型，效果会比较好。

**首先，根据数据的结构选择一类合适的模型**。如果项目是以固定大小的向量作为输入的监督学习，那么可以使用全连接的前馈网络。
如果输入已知的拓扑结构（例如，输入的是图像），那么可以使用卷积网络。
在这些情况下，刚开始可以使用某些分段线性单元（ReLU或者其扩展，如Leaky ReLU、PReLU和maxout）。
如果输入或输出是一个序列，可以使用门控循环网络（LSTM或GRU）。

具有衰减学习率以及动量的SGD是优化算法一个合理的选择
（流行的衰减方法有，衰减到固定最低学习率的线性衰减、指数衰减，或每次发生验证错误停滞时将学习率降低2～10倍，这些衰减方法在不同问题上好坏不一）。
另一个非常合理的选择是Adam算法。
**批标准化**对优化性能有着显著的影响，特别是对卷积网络和具有sigmoid非线性函数的网络而言。
虽然在最初的基准中忽略批标准化是合理的，然而当优化似乎出现问题时，应该立刻使用批标准化。

除非训练集包含数千万以及更多的样本，否则项目应该在一开始就包含一些温和的正则化。
提前终止也被普遍采用。Dropout也是一个很容易实现，且兼容很多模型和训练算法的出色正则化项。
批标准化有时也能降低泛化误差，此时可以省略Dropout步骤，因为用于标准化变量的统计量估计本身就存在噪声。

如果我们的任务和另一个被广泛研究的任务相似，那么通过**复制先前研究中已知性能良好的模型和算法**，可能会得到很好的效果，
甚至可以从该任务中**复制一个训练好的模型**。
例如，通常会使用在ImageNet上训练好的卷积网络的特征来解决其他计算机视觉任务（Girshick et al. ，2015）。

## 3. 是否需要收集更多数据？
在建立第一个端到端的系统后，就可以度量算法性能并决定如何改进算法。
许多机器学习新手都忍不住尝试很多不同的算法来进行改进。然而，**收集更多的数据**往往比改进学习算法要有用得多。

怎样判断是否要收集更多的数据？

首先，确定训练集上的性能是否可接受。
如果模型在训练集上的性能就很差，学习算法都不能在训练集上学习出良好的模型，那么就没必要收集更多的数据，
可以尝试增加更多的网络层或每层增加更多的隐藏单元，以增加模型的规模。
此外，也可以尝试调整学习率等超参数的措施来改进学习算法。
如果更大的模型和仔细调试的优化算法效果不佳，那么问题可能源自**训练数据的质量**。
数据可能含太多噪声，或是可能不包含预测输出所需的正确输入。这意味着我们需要重新开始，收集更干净的数据或是收集特征更丰富的数据集。

如果训练集上的性能是可接受的，那么我们开始度量测试集上的性能。如果测试集上的性能也是可以接受的，那么就顺利完成了。

如果测试集上的性能比训练集的要差得多，那么收集更多的数据是最有效的解决方案之一。
这时主要的考虑是收集更多数据的代价和可行性，其他方法降低测试误差的代价和可行性，以及增加数据数量能否显著提升测试集性能。
在拥有百万甚至上亿用户的大型网络公司，收集大型数据集是可行的，并且这样做的成本可能比其他方法要少很多，所以答案几乎总是收集更多的训练数据。
例如，收集大型标注数据集是解决对象识别问题的主要因素之一。在其他情况下，如医疗应用，收集更多的数据可能代价很高或者不可行。
一个可以替代的简单方法是降低模型大小或是改进正则化（调整超参数，如权重衰减系数，或是加入正则化策略，如Dropout）。
如果调整正则化超参数后，训练集性能和测试集性能之间的差距还是不可接受，那么收集更多的数据是可取的。

在决定是否收集更多的数据时，也需要**确定收集多少数据**。
绘制曲线显示训练集规模和泛化误差之间的关系是很有帮助的。根据走势延伸曲线，可以预测还需要多少训练数据来达到一定的性能。
通常，加入总数目一小部分的样本不会对泛化误差产生显著的影响。因此，建议**在对数尺度上考虑训练集的大小**，例如在后续的实验中倍增样本数目。

如果收集更多的数据是不可行的，那么改进泛化误差的唯一方法是改进学习算法本身。这属于研究领域，并非对应用实践者的建议。
